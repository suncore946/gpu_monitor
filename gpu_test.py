import torch
import time
import os
import sys
import argparse
import multiprocessing

def gpu_stress_task(gpu_id, duration, mem_gb):
    """
    å•ä¸ª GPU çš„å‹æµ‹ä»»åŠ¡å‡½æ•°
    """
    try:
        # åœ¨ spawn æ¨¡å¼ä¸‹ï¼Œå­è¿›ç¨‹è¿›å…¥å‡½æ•°æ—¶æ‰çœŸæ­£åˆå§‹åŒ– CUDA
        torch.cuda.set_device(gpu_id)
        
        pid = os.getpid()
        print(f"[{gpu_id}] ğŸš€ å¯åŠ¨å‹æµ‹ | PID: {pid}")
        print(f"[{gpu_id}] ğŸ’¾ å°è¯•åˆ†é…æ˜¾å­˜: {mem_gb}GB")

        # 1. æ˜¾å­˜å ä½
        try:
            # 1GB float32 â‰ˆ 2.68äº¿ä¸ªå…ƒç´  (1024*1024*256)
            tensor_size = (int(mem_gb * 256), 1024, 1024)
            x = torch.rand(tensor_size, device=f'cuda:{gpu_id}')
            print(f"[{gpu_id}] âœ… æ˜¾å­˜åˆ†é…æˆåŠŸ")
        except RuntimeError as e:
            print(f"[{gpu_id}] âŒ æ˜¾å­˜ä¸è¶³æˆ–å‡ºé”™: {e}")
            return

        # 2. è®¡ç®—è´Ÿè½½
        print(f"[{gpu_id}] ğŸ”¥ å¼€å§‹çŸ©é˜µè¿ç®—...")
        
        # åˆ›å»ºè®¡ç®—çŸ©é˜µ (4000x4000 é€‚åˆäº§ç”Ÿé«˜è´Ÿè½½)
        compute_tensor = torch.randn(4000, 4000, device=f'cuda:{gpu_id}')
        
        start_time = time.time()
        while time.time() - start_time < duration:
            torch.mm(compute_tensor, compute_tensor)
            
        print(f"[{gpu_id}] âœ… æµ‹è¯•å®Œæˆ")

    except Exception as e:
        print(f"[{gpu_id}] âŒ é”™è¯¯: {e}")

def main():
    parser = argparse.ArgumentParser(description="å¤šå¡ GPU å¹¶å‘å‹åŠ›æµ‹è¯•è„šæœ¬")
    parser.add_argument('--duration', type=int, default=60, help='æŒç»­æ—¶é—´ (ç§’)')
    parser.add_argument('--mem_gb', type=int, default=4, help='æ¯å¼ å¡å ç”¨çš„æ˜¾å­˜å¤§å° (GB)')
    parser.add_argument('--gpus', type=str, default='all', help='æŒ‡å®š GPU ID (å¦‚ "0,1" æˆ– "all")')
    args = parser.parse_args()

    # ç®€å•çš„æ£€æŸ¥ï¼Œæ³¨æ„ä¸»è¿›ç¨‹å°½é‡å°‘è°ƒç”¨ CUDA å‡½æ•°ï¼Œæˆ–è€…ç¡®ä¿è°ƒç”¨å‰å·²è®¾ç½® spawn
    if not torch.cuda.is_available():
        print("âŒ é”™è¯¯: æœªæ£€æµ‹åˆ° CUDA ç¯å¢ƒ")
        sys.exit(1)

    total_gpus = torch.cuda.device_count()
    
    # è§£æç›®æ ‡ GPU
    if args.gpus == 'all':
        target_gpus = list(range(total_gpus))
    else:
        target_gpus = [int(x) for x in args.gpus.split(',')]

    print(f"========================================")
    print(f"ğŸ¯ ç›®æ ‡æ˜¾å¡: {target_gpus}")
    print(f"â³ æŒç»­æ—¶é—´: {args.duration}s | æ˜¾å­˜: {args.mem_gb}GB")
    print(f"========================================")

    processes = []
    
    for gpu_id in target_gpus:
        p = multiprocessing.Process(
            target=gpu_stress_task, 
            args=(gpu_id, args.duration, args.mem_gb)
        )
        p.start()
        processes.append(p)

    for p in processes:
        p.join()

    print("âœ… æ‰€æœ‰æµ‹è¯•ç»“æŸ")

if __name__ == "__main__":
    # ã€å…³é”®ä¿®æ”¹ã€‘è®¾ç½®å¯åŠ¨æ–¹æ³•ä¸º spawn
    # å¿…é¡»æ”¾åœ¨ if __name__ == "__main__": çš„ç¬¬ä¸€è¡Œ
    try:
        multiprocessing.set_start_method('spawn')
    except RuntimeError:
        # å¦‚æœå·²ç»è®¾ç½®è¿‡ï¼ˆä¾‹å¦‚åœ¨æŸäº›ç¯å¢ƒä¸­ï¼‰ï¼Œåˆ™å¿½ç•¥é”™è¯¯
        pass
    
    main()

